# Kafka, Apache Avro and Confluent Platform with springboot
Kafka :
We need streaming because we  need to backup data, monitoring or detecting abnormalities,creating new streams from the original streams ,drip feed events into columnar or nosql databases.
There are a variety of schema technologies and they are known as data serialization systems. We have malready mentioned some populer ones with our tutorials.
Today we will talk about Avro, one of the most mature and experienced serialization systems.
- It is eveloped as part of the Apache Hadoop project
- Itâ€™s schema language is json based.
- Avro (IDL) Interface Definition Language syntax is like  C 
- Avro has 2 representations, a human-readable JSON encoding and  binary encoding format
- Avro uses a .avsc file
- It has a poor compatibility for programming languagesi when compared witk other data serialization systems

